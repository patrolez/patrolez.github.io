fragment_downloaded_cb({"url":"tutorials/ios/video.html#the-gstreamer-backend","fragment":"The GStreamer Backend\nThe GStreamerBackend class performs all GStreamer-related tasks and\noffers a simplified interface to the application, which does not need to\ndeal with all the GStreamer details. When it needs to perform any UI\naction, it does so through a delegate, which is expected to adhere to\nthe GStreamerBackendDelegate protocol:\nGStreamerBackend.m\nThe main differences with the previous tutorial are related to the\nhandling of the VideoOverlay interface:\nThe class is expanded to keep track of the video sink element in the\npipeline and the UIView * onto which rendering is to occur.\nThe constructor accepts the UIView * as a new parameter, which, at\nthis point, is simply remembered in ui_video_view.\nThen, in the app_function, the pipeline is constructed. This time we\nbuild a video pipeline using a simple videotestsrc element with a\nwarptv to add some spice. The video sink is autovideosink, which\nchoses the appropriate sink for the platform (currently,\nglimagesink is the only option for\niOS).\nOnce the pipeline is built, we set it to READY. In this state, dataflow\nhas not started yet, but the caps of adjacent elements have been\nverified to be compatible and their pads have been linked. Also, the\nautovideosink has already instantiated the actual video sink so we can\nask for it immediately.\nThe gst_bin_get_by_interface() method will examine the whole pipeline\nand return a pointer to an element which supports the requested\ninterface. We are asking for the VideoOverlay interface, explained in\nBasic tutorial 5: GUI toolkit integration,\nwhich controls how to perform rendering into foreign (non-GStreamer)\nwindows. The internal video sink instantiated by autovideosink is the\nonly element in this pipeline implementing it, so it will be returned.\nOnce we have the video sink, we inform it of the UIView to use for\nrendering, through the gst_video_overlay_set_window_handle() method.\n"});