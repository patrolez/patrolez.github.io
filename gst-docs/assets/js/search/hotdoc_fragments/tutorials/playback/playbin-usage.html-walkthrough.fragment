fragment_downloaded_cb({"url":"tutorials/playback/playbin-usage.html#walkthrough","fragment":"Walkthrough\nWe start, as usual, putting all our variables in a structure, so we can\npass it around to functions. For this tutorial, we need the amount of\nstreams of each type, and the currently playing one. Also, we are going\nto use a different mechanism to wait for messages that allows\ninteractivity, so we need a GLib's main loop object.\nLater we are going to set some of playbin's flags. We would like to\nhave a handy enum that allows manipulating these flags easily, but since\nplaybin is a plug-in and not a part of the GStreamer core, this enum\nis not available to us. The “trick” is simply to declare this enum in\nour code, as it appears in the playbin documentation: GstPlayFlags.\nGObject allows introspection, so the possible values for these flags can\nbe retrieved at runtime without using this trick, but in a far more\ncumbersome way.\nForward declarations for the two callbacks we will be using.\nhandle_message for the GStreamer messages, as we have already seen,\nand handle_keyboard for key strokes, since this tutorial is\nintroducing a limited amount of interactivity.\nWe skip over the creation of the pipeline, the instantiation of\nplaybin and pointing it to our test media through the uri\nproperty. playbin is in itself a pipeline, and in this case it is the\nonly element in the pipeline, so we skip completely the creation of the\npipeline, and use directly the  playbin element.\nWe focus on some of the other properties of playbin, though:\nplaybin's behavior can be changed through its flags property, which\ncan have any combination of GstPlayFlags. The most interesting values\nare:\nIn our case, for demonstration purposes, we are enabling audio and video\nand disabling subtitles, leaving the rest of flags to their default\nvalues (this is why we read the current value of the flags with\ng_object_get() before overwriting it with g_object_set()).\nThis property is not really useful in this example.\nconnection-speed informs playbin of the maximum speed of our network\nconnection, so, in case multiple versions of the requested media are\navailable in the server, playbin chooses the most appropriate. This is\nmostly used in combination with streaming protocols like hls or\nrtsp.\nWe have set all these properties one by one, but we could have all of\nthem with a single call to g_object_set():\nThis is why g_object_set() requires a NULL as the last parameter.\nThese lines connect a callback function to the standard input (the\nkeyboard). The mechanism shown here is specific to GLib, and not really\nrelated to GStreamer, so there is no point in going into much depth.\nApplications normally have their own way of handling user input, and\nGStreamer has little to do with it besides the Navigation interface\ndiscussed briefly in [Tutorial 17: DVD playback].\nTo allow interactivity, we will no longer poll the GStreamer bus\nmanually. Instead, we create a GMainLoop(GLib main loop) and set it\nrunning with g_main_loop_run(). This function blocks and will not\nreturn until g_main_loop_quit() is issued. In the meantime, it will\ncall the callbacks we have registered at the appropriate\ntimes: handle_message when a message appears on the bus, and\nhandle_keyboard when the user presses any key.\nThere is nothing new in handle_message, except that when the pipeline\nmoves to the PLAYING state, it will call the analyze_streams function:\nAs the comment says, this function just gathers information from the\nmedia and prints it on the screen. The number of video, audio and\nsubtitle streams is directly available through the n-video,\nn-audio and n-text properties.\nNow, for each stream, we want to retrieve its metadata. Metadata is\nstored as tags in a GstTagList structure, which is a list of data\npieces identified by a name. The GstTagList associated with a stream\ncan be recovered with g_signal_emit_by_name(), and then individual\ntags are extracted with the gst_tag_list_get_* functions\nlike gst_tag_list_get_string() for example.\n\nThis rather unintuitive way of retrieving the tag list\nis called an Action Signal. Action signals are emitted by the\napplication to a specific element, which then performs an action and\nreturns a result. They behave like a dynamic function call, in which\nmethods of a class are identified by their name (the signal's name)\ninstead of their memory address. These signals are listed In the\ndocumentation along with the regular signals, and are tagged “Action”.\nSee playbin, for example.\nplaybin defines 3 action signals to retrieve metadata:\nget-video-tags, get-audio-tags and get-text-tags. The name if the\ntags is standardized, and the list can be found in the GstTagList\ndocumentation. In this example we are interested in the\nGST_TAG_LANGUAGE_CODE of the streams and their GST_TAG_*_CODEC\n(audio, video or text).\nOnce we have extracted all the metadata we want, we get the streams that\nare currently selected through 3 more properties of playbin:\ncurrent-video, current-audio and current-text.\nIt is interesting to always check the currently selected streams and\nnever make any assumption. Multiple internal conditions can make\nplaybin behave differently in different executions. Also, the order in\nwhich the streams are listed can change from one run to another, so\nchecking the metadata to identify one particular stream becomes crucial.\nFinally, we allow the user to switch the running audio stream. This very\nbasic function just reads a string from the standard input (the\nkeyboard), interprets it as a number, and tries to set the\ncurrent-audio property of playbin (which previously we have only\nread).\nBear in mind that the switch is not immediate. Some of the previously\ndecoded audio will still be flowing through the pipeline, while the new\nstream becomes active and is decoded. The delay depends on the\nparticular multiplexing of the streams in the container, and the length\nplaybin has selected for its internal queues (which depends on the\nnetwork conditions).\nIf you execute the tutorial, you will be able to switch from one\nlanguage to another while the movie is running by pressing 0, 1 or 2\n(and ENTER). This concludes this tutorial.\n\n\n\n Flag\n Description\n\n\n\n\n GST_PLAY_FLAG_VIDEO\n Enable video rendering. If this flag is not set, there will be no video output.\n\n\n GST_PLAY_FLAG_AUDIO\n Enable audio rendering. If this flag is not set, there will be no audio output.\n\n\n GST_PLAY_FLAG_TEXT\n Enable subtitle rendering. If this flag is not set, subtitles will not be shown in the video output.\n\n\n GST_PLAY_FLAG_VIS\n Enable rendering of visualisations when there is no video stream. Playback tutorial 6: Audio visualization goes into more details.\n\n\n GST_PLAY_FLAG_DOWNLOAD\n See Basic tutorial 12: Streaming  and Playback tutorial 4: Progressive streaming.\n\n\n GST_PLAY_FLAG_BUFFERING\n See Basic tutorial 12: Streaming  and Playback tutorial 4: Progressive streaming.\n\n\n GST_PLAY_FLAG_DEINTERLACE\n If the video content was interlaced, this flag instructs playbin to deinterlace it before displaying it.\n\n\n\n"});