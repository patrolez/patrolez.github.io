fragment_downloaded_cb({"url":"additional/design/overview.html#introduction","fragment":"Introduction\nGStreamer is a set of libraries and plugins that can be used to\nimplement various multimedia applications ranging from desktop players,\naudio/video recorders, multimedia servers, transcoders, etc.\nApplications are built by constructing a pipeline composed of elements.\nAn element is an object that performs some action on a multimedia stream\nsuch as:\nElements have input and output pads called sink and source pads in\nGStreamer. An application links elements together on pads to construct a\npipeline. Below is an example of an ogg/vorbis playback pipeline.\nThe filesrc element reads data from a file on disk. The oggdemux element\ndemultiplexes the data and sends a compressed audio stream to the vorbisdec\nelement. The vorbisdec element decodes the compressed data and sends it\nto the alsasink element. The alsasink element sends the samples to the\naudio card for playback.\nDownstream and upstream are the terms used to describe the direction in\nthe Pipeline. From source to sink is called \"downstream\" and \"upstream\"\nis from sink to source. Dataflow always happens downstream.\nThe task of the application is to construct a pipeline as above using\nexisting elements. This is further explained in the pipeline building\ntopic.\nThe application does not have to manage any of the complexities of the\nactual dataflow/decoding/conversions/synchronisation etc. but only calls\nhigh level functions on the pipeline object such as PLAY/PAUSE/STOP.\nThe application also receives messages and notifications from the\npipeline such as metadata, warning, error and EOS messages.\nIf the application needs more control over the graph it is possible to\ndirectly access the elements and pads in the pipeline.\n\nread a file\ndecode or encode between formats\ncapture from a hardware device\nrender to a hardware device\nmix or multiplex multiple streams\n\n"});