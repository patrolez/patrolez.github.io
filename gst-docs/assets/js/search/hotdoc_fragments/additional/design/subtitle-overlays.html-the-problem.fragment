fragment_downloaded_cb({"url":"additional/design/subtitle-overlays.html#the-problem","fragment":"The Problem\nIn the case of such hardware-accelerated decoding, the decoder will not\noutput raw pixels that can easily be manipulated. Instead, it will\noutput hardware/API-specific objects that can later be used to render a\nframe using the same API.\nEven if we could transform such a buffer into raw pixels, we most likely\nwould want to avoid that, in order to avoid the need to map the data\nback into system memory (and then later back to the GPU). It's much\nbetter to upload the much smaller encoded data to the GPU/DSP and then\nleave it there until rendered.\nBefore GstVideoOverlayComposition playbin only supported subtitles on\ntop of raw decoded video. It would try to find a suitable overlay element\nfrom the plugin registry based on the input subtitle caps and the rank.\n(It is assumed that we will be able to convert any raw video format into\nany format required by the overlay using a converter such as videoconvert.)\nIt would not render subtitles if the video sent to the sink is not raw\nYUV or RGB or if conversions had been disabled by setting the\nnative-video flag on playbin.\nSubtitle rendering is considered an important feature. Enabling\nhardware-accelerated decoding by default should not lead to a major\nfeature regression in this area.\nThis means that we need to support subtitle rendering on top of non-raw\nvideo.\n"});