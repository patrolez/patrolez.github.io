fragment_downloaded_cb({"url":"application-development/advanced/clocks.html#clocks-and-synchronization-in-gstreamer","fragment":"Clocks and synchronization in GStreamer\nWhen playing complex media, each sound and video sample must be played\nin a specific order at a specific time. For this purpose, GStreamer\nprovides a synchronization mechanism.\nGStreamer provides support for the following use cases:\nNon-live sources with access faster than playback rate. This is the\ncase where one is reading media from a file and playing it back in a\nsynchronized fashion. In this case, multiple streams need to be\nsynchronized, like audio, video and subtitles.\nCapture and synchronized muxing/mixing of media from multiple live\nsources. This is a typical use case where you record audio and video\nfrom a microphone/camera and mux it into a file for storage.\nStreaming from (slow) network streams with buffering. This is the\ntypical web streaming case where you access content from a streaming\nserver using HTTP.\nCapture from live source and playback with configurable latency. This\nis used, for example, when capturing from a camera, applying an\neffect and displaying the result. It is also used when streaming\nlow latency content over a network with UDP.\nSimultaneous live capture and playback from prerecorded content.\nThis is used in audio recording cases where you play a previously\nrecorded audio and record new samples, the purpose is to have the\nnew audio perfectly in sync with the previously recorded data.\nGStreamer uses a GstClock object, buffer timestamps and a SEGMENT\nevent to synchronize streams in a pipeline as we will see in the next\nsections.\n\n\nNon-live sources with access faster than playback rate. This is the\ncase where one is reading media from a file and playing it back in a\nsynchronized fashion. In this case, multiple streams need to be\nsynchronized, like audio, video and subtitles.\n\n\nCapture and synchronized muxing/mixing of media from multiple live\nsources. This is a typical use case where you record audio and video\nfrom a microphone/camera and mux it into a file for storage.\n\n\nStreaming from (slow) network streams with buffering. This is the\ntypical web streaming case where you access content from a streaming\nserver using HTTP.\n\n\nCapture from live source and playback with configurable latency. This\nis used, for example, when capturing from a camera, applying an\neffect and displaying the result. It is also used when streaming\nlow latency content over a network with UDP.\n\n\nSimultaneous live capture and playback from prerecorded content.\nThis is used in audio recording cases where you play a previously\nrecorded audio and record new samples, the purpose is to have the\nnew audio perfectly in sync with the previously recorded data.\n\n\n"});